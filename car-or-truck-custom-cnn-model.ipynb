{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/drondasgupta/car-or-truck-custom-cnn-model?scriptVersionId=107747435\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-17T13:52:25.119996Z","iopub.execute_input":"2022-09-17T13:52:25.120325Z","iopub.status.idle":"2022-09-17T13:52:25.140729Z","shell.execute_reply.started":"2022-09-17T13:52:25.12025Z","shell.execute_reply":"2022-09-17T13:52:25.139869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Objective\nThe objective of this code is to create a Convolutional Neural Net (CNN) that takes a 2D image and classifies it as a 'Car' or a 'Truck', depending on its features.\n\nFirst, we will import and set up a few important libraries:","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib import gridspec\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory","metadata":{"execution":{"iopub.status.busy":"2022-09-17T13:52:25.14236Z","iopub.execute_input":"2022-09-17T13:52:25.143054Z","iopub.status.idle":"2022-09-17T13:52:30.452085Z","shell.execute_reply.started":"2022-09-17T13:52:25.143018Z","shell.execute_reply":"2022-09-17T13:52:30.45108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='magma')\n# warnings.filterwarnings(\"ignore\") # to clean up output cells","metadata":{"execution":{"iopub.status.busy":"2022-09-17T13:52:30.455485Z","iopub.execute_input":"2022-09-17T13:52:30.456356Z","iopub.status.idle":"2022-09-17T13:52:30.461975Z","shell.execute_reply.started":"2022-09-17T13:52:30.456317Z","shell.execute_reply":"2022-09-17T13:52:30.460799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we are going to load our data, which consists of one folder of training images (training set) and one folder of validation images (validation set).\n\nWe will also create a pipeline that modifies our image to a float value and autotunes it.","metadata":{}},{"cell_type":"code","source":"# Load training and validation sets\nds_train_ = image_dataset_from_directory(\n    '../input/car-or-truck/train',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=True,\n)\nds_valid_ = image_dataset_from_directory(\n    '../input/car-or-truck/valid',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=False,\n)\n\n# Data Pipeline\ndef convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds_train = (\n    ds_train_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_valid = (\n    ds_valid_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T13:52:30.464609Z","iopub.execute_input":"2022-09-17T13:52:30.46581Z","iopub.status.idle":"2022-09-17T13:52:39.370633Z","shell.execute_reply.started":"2022-09-17T13:52:30.465757Z","shell.execute_reply":"2022-09-17T13:52:39.368885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time to create our model.\n\nFor a single convolutional block, we are using a 3x3 kernel, 'relu' activation, ","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.InputLayer(input_shape=[128, 128, 3]),\n\n    # Block One\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Block Two\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Block Three\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Head\n    layers.BatchNormalization(renorm=True),\n    layers.Flatten(),\n    layers.Dense(8, activation='relu'),\n    layers.Dense(1, activation='sigmoid'),\n])","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:22:57.030573Z","iopub.execute_input":"2022-09-17T14:22:57.030976Z","iopub.status.idle":"2022-09-17T14:22:57.374205Z","shell.execute_reply.started":"2022-09-17T14:22:57.030943Z","shell.execute_reply":"2022-09-17T14:22:57.373294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer = tf.keras.optimizers.Adam(epsilon=0.01),\n    # YOUR CODE HERE: Add loss and metric\n    loss = 'binary_crossentropy',\n    metrics = ['binary_accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:22:58.829887Z","iopub.execute_input":"2022-09-17T14:22:58.830247Z","iopub.status.idle":"2022-09-17T14:22:58.841091Z","shell.execute_reply.started":"2022-09-17T14:22:58.830214Z","shell.execute_reply":"2022-09-17T14:22:58.840151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    ds_train,\n    validation_data = ds_valid,\n    epochs = 50\n)\n\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:22:59.780117Z","iopub.execute_input":"2022-09-17T14:22:59.780505Z","iopub.status.idle":"2022-09-17T14:30:05.147254Z","shell.execute_reply.started":"2022-09-17T14:22:59.780473Z","shell.execute_reply":"2022-09-17T14:30:05.146287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, the training loss reduces sharply after 10 epochs compared to the validation loss. Similarly, the validation accuracy plateaus at roughly 90% from around 30 epochs, while the training accuracy flatlines at almost 100%.\n\nThis suggests the model is overfitting, and we need to employ some regulartization controls.","metadata":{}},{"cell_type":"markdown","source":"## Dropout\nDropout can be added to dense, convolutional and pooling layers by putting the following line of code after the layer (rate is a hyperparameter, selected as 0.3 here):","metadata":{}},{"cell_type":"code","source":"layers.Dropout(rate = 0.3)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T13:55:15.993256Z","iopub.execute_input":"2022-09-17T13:55:15.993681Z","iopub.status.idle":"2022-09-17T13:55:16.003522Z","shell.execute_reply.started":"2022-09-17T13:55:15.993626Z","shell.execute_reply":"2022-09-17T13:55:16.002274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In a CNN, it is usually only used after the pooling layers.","metadata":{}},{"cell_type":"markdown","source":"## Early Stopping\nEarly stopping can be added to prevent overfitting by stopping the learning when validation loss stops increasing. It can be defined as a callbacks.EarlyStopping object and added as an array for the 'callbacks' hyperparameter in model.fit():","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import callbacks\n\nearly_stopping = callbacks.EarlyStopping(\n    min_delta = 0.001,\n    patience = 5,\n    restore_best_weights = True\n)\n\n# history = model.fit(\n#     X_train, y_train,\n#     validation_data = (X_valid, y_valid),\n#     callbacks = [early_stopping]\n# )","metadata":{"execution":{"iopub.status.busy":"2022-09-17T13:55:16.007555Z","iopub.execute_input":"2022-09-17T13:55:16.00845Z","iopub.status.idle":"2022-09-17T13:55:16.013291Z","shell.execute_reply.started":"2022-09-17T13:55:16.008413Z","shell.execute_reply":"2022-09-17T13:55:16.012536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation\nData augmentation gives the model a more generalized input by performing linear transformation on the images (for this dataset, rotation, contrast and horizontal flips make the most sense).","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers.experimental import preprocessing\n# augment = keras.Sequential([\n#     # preprocessing.RandomContrast(factor=0.5),\n#     preprocessing.RandomFlip(mode='horizontal'), # meaning, left-to-right\n#     # preprocessing.RandomFlip(mode='vertical'), # meaning, top-to-bottom\n#     preprocessing.RandomWidth(factor=0.15), # horizontal stretch\n#     preprocessing.RandomRotation(factor=0.03),\n#     preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n# ])","metadata":{"execution":{"iopub.status.busy":"2022-09-17T13:55:16.014631Z","iopub.execute_input":"2022-09-17T13:55:16.015492Z","iopub.status.idle":"2022-09-17T13:55:16.026082Z","shell.execute_reply.started":"2022-09-17T13:55:16.015456Z","shell.execute_reply":"2022-09-17T13:55:16.024996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sample regularized model","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.InputLayer(input_shape=[128, 128, 3]),\n    \n    # Data Augmentation\n    preprocessing.RandomContrast(factor=0.10),\n    preprocessing.RandomFlip(mode='horizontal'),\n    preprocessing.RandomRotation(factor=0.10),\n\n    # Block One\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n    layers.Dropout(rate = 0.3),\n\n    # Block Two\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n    layers.Dropout(rate = 0.3),\n\n    # Block Three\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n    layers.Dropout(rate = 0.3),\n\n    # Head\n    layers.BatchNormalization(renorm=True),\n    layers.Flatten(),\n    layers.Dense(8, activation='relu'),\n    layers.Dropout(rate = 0.3),\n    layers.Dense(1, activation='sigmoid'),\n])","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:11:51.801439Z","iopub.execute_input":"2022-09-17T14:11:51.80181Z","iopub.status.idle":"2022-09-17T14:11:52.01509Z","shell.execute_reply.started":"2022-09-17T14:11:51.801778Z","shell.execute_reply":"2022-09-17T14:11:52.014178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(epsilon=0.01)\nmodel.compile(\n    optimizer=optimizer,\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\n\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=50,\n)\n\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:12:00.030047Z","iopub.execute_input":"2022-09-17T14:12:00.030435Z","iopub.status.idle":"2022-09-17T14:19:20.69485Z","shell.execute_reply.started":"2022-09-17T14:12:00.030398Z","shell.execute_reply":"2022-09-17T14:19:20.693952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, both the training and validation loss keep decreasing, and both training and validation accuracy keep increasing. This means that our changes were successful in preventing the model from overfitting.","metadata":{}},{"cell_type":"markdown","source":"## Result\nThus, we have successfully created a CNN that can classify Cars vs. Trucks given an image, with around 90% accuracy.","metadata":{}}]}